{
    "contents" : "library(MCMCpack)\n# Generating the data\nwordtypes <- read.table(file=\"~/Dropbox/Academic notes/5 A/STAT 444/Project/listingwords.txt\")\n# Dont even really need to define the topics like this, however, these words are essentially the \"most frequently occuring\"\n# or highest pdf valued words in each topic.\ntopic1 <- c(\"kitchen\",\"basement\",\"entrance\",\"beautiful\",\"detached\",\"hardwood\",\"stunning\",\"bedroom\",\"roof\",\n            \"4\",\"location\",\"painted\",\"prime\",\"backsplash\",\"bright\",\"ensuite\",\"excellent\",\"famous\",\"granite\",\n            \"interlock\",\"laundry\",\"maintained\",\"master\",\"sidewalk\",\"upgraded\")\ntopic2 <- c(\"yard\",\"apartment\",\"backyard\",\"bathroom\",\"beauty\",\"bedrooms\",\"brick\",\"ceramic\",\"community\",\"deck\",\n            \"demand\",\"drive\",\"family\",\"finished\",\"fireplace\",\"freshly\",\"front\",\n            \"furnace\",\"garage\",\"high\",\"home\",\"house\",\"landscaped\",\"layout\",\"new\")\ntopic3 <- c(\"oak\",\"renovated\",\"school\",\"schools\",\"walk\",\"windows\",\"2015\",\"3\",\"absolutely\",\"amazing\",\"amenities\",\n            \"appliances\",\"area\",\"bath\",\"bathrooms\",\"baths\",\"bottom\",\"breakfast\",\"close\",\"closet\",\"concept\",\n            \"countertop\",\"crown\",\"desirable\",\"dishwasher\")\ntopic4 <- c(\"distance\",\"enclosed\",\"extra\",\"features\",\"fenced\",\"fridges\",\"fully\",\"gleaming\",\"gorgeous\",\"grand\",\n            \"hallway\",\"huge\",\"immaculate\",\"in\",\"lake\",\"landscaping\",\"large\",\"lighting\",\"lights\",\"lot\",\"lots\",\"luxurious\",\n            \"main\",\"newer\",\"open\")\ntopic5 <- c(\"park\",\"parking\",\"parks\",\"porch\",\"pot\",\"potential\",\"practical\",\"private\",\"public\",\"restaurants\",\n            \"room\",\"shed\",\"shopping\",\"sought\",\"spaces\",\"spacious\",\"tank\",\"transit\",\"updated\",\"virtual\",\n            \"walking\",\"walkway\",\"washrooms\",\"water\",\"well\")\ntopic6 <- c(\"wide\",\"1970\",\"fancy\",\"mahogany\",\"!\",\"modern\",\"tranquil\",\".\",\"?\",\"quiet\",\"young\",\"youthful\",\n            \"upcoming\",\"cinema\",\"grocery\",\"gym\",\"trail\",\"cozy\",\"5\",\"2011\",\"loud\",\"1966\",\"historic\",\"winter\",\"available\")\n# Random variables\nset.seed(1)\n# Creating random parameters for each poisson variable used to create \n# listing lengths\nlambdas <- 1:10\nfor(i in 1:10){ lambdas[i] <- rgamma(1,18)}\n# For each document, generate a random length/ number of unique word types\nm <- 1:10\nfor(i in 1:10){ m[i] <- rpois(1,lambdas[i])}\n# For each topic, making a distribution for each word\nP <- matrix(0, ncol = 150,nrow = 6)\nfor(k in 1:6){ P[k,] <- rdirichlet(1,rep(0.05,150))}\n# Determining the topic distribution for each documents i\nZeta <- matrix(0, ncol = 6,nrow = 10)\nfor(i in 1:10) { \n        Zeta[i,] <- rdirichlet(1,rep(0.1,6))\n}\n# Simulating the topic for each of the mi word types in document i, position m\nk <-   matrix(0, ncol = 30,nrow = 10)\nfor(i in 1:10) { \n        k[i,] <- rmultinom(1,6,Zeta[i,]) \n        k[i,k[i,] == 0] <- 1\n        k[i,k[i,] == 4] <- 2\n        k[i,k[i,] == 6] <- 3\n        k[i,k[i,] == 5] <- 4\n        k[i,k[i,] == 2] <- 5\n        # Adding zeros instead of topics for empty spots in documents\n        n <- m[i]\n        if(n < ncol(k)){\n                # Extra spaces generates\n                fill <- rep(0,ncol(k) - n)\n                k[i,(n+1):ncol(k)] <- fill        \n        }\n}\n# indices for w given the topic for each spot m in doc i\nw.given.k.index <- k\n# list to hold the generated actual word types for each spot m in doc i\nw.given.k <- list()\n# Pulling word types based on the distribution of mth word, ith topic\nfor(i in 1:10){\n        for(j in 1:30){\n                if(w.given.k.index[i,j] != 0){\n                        w.given.k.index[i,j] <- which(rmultinom(1,1,\n                                                                P[w.given.k.index[i,j],]) != 0)\n                } else {\n                        w.given.k.index[i,j] <- 132\n                }\n        }\n        \n        w.given.k[[i]] <- wordtypes[w.given.k.index[i,],1] \n}\nw.given.k <- data.frame(matrix(unlist(w.given.k), nrow=10, byrow=T))\naddemptyString <- function(x){\n        if(is.factor(x)) return(factor(x, levels=c(levels(x), \"\")))\n        return(x)\n}\nw.given.k <- as.data.frame(lapply(w.given.k, addemptyString))\nw.given.k[w.given.k == \".\"] <- \"\"\n# Vocabulary of M = 150 word types\n# Words in n = 10 documents generated by a mixture of K = 6 topics each defined by \n# probability distributions P1..P6 over the 150 word types \n\n# W\nwords <-scan(\"~/Dropbox/Academic notes/5 A/STAT 444/Project/listingblob.txt\",\n             what=\"char\", sep=\"\\n\")\n# Converting the read in tect listings to lower case\nblobi <-tolower(words)\n# Splitting the text into individual word types\nblob.list<-strsplit(blobi, \"\\\\W+\", perl=TRUE)\n# Changing a list of word types into an R vector data type\nblob.words.vector<-unlist(blob.list)\nsort(table(blob.words.vector),decreasing = TRUE)\n# Vector of all the unique word types occurring in listings\nallwords <- unique(blob.words.vector)\n# Creating a matrix W to hold the word type counts\nW <- matrix(0,ncol=length(allwords),nrow=10)\n# Assigning the counts of the word types in W\nfor(i in 1:10){\n        for(j in 1:length(names(blobs[[i]]))){\n                W[i,which((names(blobs[[i]])[j] == allwords) ==1)] <- blobs[[i]][[j]]\n                }\n        }\n# Reading in the randomly generated listings from a text file\nblob <-scan(\"~/Dropbox/Academic notes/5 A/STAT 444/Project/sample-listings.txt\",\n                          what=\"char\", sep=\"\\n\")\n# Creating a list to hold the word type counts for each listing\nblobs <- list()\nfor(i in 1:10){\nblobi <-tolower(blob[i])\nblob.list<-strsplit(blobi, \"\\\\W+\", perl=TRUE)\nblob.words.vector<-unlist(blob.list)\nblob.freq.list<-table(blob.words.vector)\nprint(length(blob.freq.list))\nblobs[[i]] <- blob.freq.list\n}\n# Creating a list to hold the bigrams occurring in each listing\nBig <- list()\n# Looping through each listing and creating a list of the bigrams occuring in each one\nfor(i in 1:10){\n        blobi <-tolower(blob[i])\n        blob.list<-strsplit(blobi, \"\\\\W+\", perl=TRUE)\n        blob.words.vector <- unlist(blob.list)\n        bigrams <- rep(0,length(blob.words.vector) -1)\n        for(i in 1:length(blob.words.vector) -1){\n                bigrams[i] <- paste(blob.words.vector[i],blob.words.vector[i+1] , sep = \",\")\n        }\n        Big[[i]] <- bigrams\n}\n# Creating a vector with each of the bigrams that occurs in the whole corpus\nB2 <- unlist(Big)\n# Getting a subset of the unique bigrams occuring in the corpus\nB3 <- unique(B2)\n# Viewing the bigrams occurring more than once\ntable(B2)[table(B2) > 1]\n# Creating a dataframe to hold the bigrams that appeared and their respective counts - initializing all to 1 occurence\nB.final <- data.frame(B3,count=rep(1,length(B3)))\ntable(B2)[table(B2) > 1]\n# Adjusting the counts of bigrams that occurred more than once [hard-coded]\nB.final[B3==\"4,bedroom\",2] <- 4\nB.final[B3==\"entrance,kitchen\",2] <- 3\nB.final[B3==\"basement,detached\",2] <- 2\nB.final[B3==\"hardwood,basement\",2] <- 2\nB.final[B3==\"kitchen,basement\",2] <- 2\nB.final[B3==\"maintained,detached\",2] <- 2\nB.final[B3==\"sidewalk,interlock\",2] <- 2\nB.final[B3==\"upgraded,ceramic\",2] <- 2\n# Data frame of all the bigrams and their rspective counts: data.frame(string int)\nB.final <- B.final[with(B.final, order(B3)), ]\n\n# Getting a full listing of all words in the corpus, disregarding different documents\nwords <-scan(\"~/Dropbox/Academic notes/5 A/STAT 444/Project/listingblob.txt\",\n            what=\"char\", sep=\"\\n\")\n# Changing the corpus to lower case\nblobi <-tolower(words)\n# Splitting the corpus into individual word tokens\nblob.list<-strsplit(blobi, \"\\\\W+\", perl=TRUE)\n# Changing the list of word tokens into a R vector data type\nblob.words.vector<-unlist(blob.list)\n# Extracting only the unique word tokens\nblob.words.vector <- unique(blob.words.vector)\n# Creating a data frame with all the possible bigrams for comparison with the list\n# of bigrams that occurred in the text\nfor(i in 1:length(blob.words.vector)){\n        for(j in 1:length(blob.words.vector)){\n                if(j == 1){\n                        column <- c()\n                        column <- rbind(column,\n                                        paste(blob.words.vector[i],\n                                              blob.words.vector[j],\n                                              sep = \",\"))\n                } else {\n                        column <- rbind(column,\n                                        paste(blob.words.vector[i],\n                                                     blob.words.vector[j],\n                                                     sep = \",\"))\n                }\n        }\n        if(i == 1){ \n                Bi <- data.frame(column)\n        }\n        else{ Bi <- data.frame(Bi,column)}\n}\n# Creating a matrix of same dimension as B to hold the counts of bigrams as the list calculated is\n# compared against the data frame with all the possibilities\nBi2 <- matrix(0, ncol = 126, nrow = 126)\n# Assigning each bigram count to its respective column in B\nfor(i in 1:nrow(Bi)){\n        for(j in 1:ncol(Bi)){\n                #B.final[,1] <- factor(B.final[,1], levels=levels(Bi[,j))\n                if(is.na(match(Bi[i,j],B.final[,1]))){\n                        Bi2[i,j] = 0\n                } else{\n                        Bi2[i,j] = B.final[match(Bi[i,j],B.final[,1]),2]\n                }\n        }\n}\nB <- Bi2\n# B is the bigram matrix\n# Coefficients for the response/s weighted sum\nBetas <- c(top1=1.5,top2=0.9,top3=.75,top4=.5,top5=.15,top6=0)\n# Response vector\n# Calculating mean prices for each listing based on the distribution of topics in the document\nmeans <- Zeta%*%Betas\n# Creating a data frame to hold the simulated listing prices\ny <- data.frame()\n# Creating the listing prices with a  normal random variable\nset.seed(1)\nfor(i in 1:10){\n        y <- rbind(y,rnorm(1,mean =means[i],sd=0.075))\n        names(y) <- \"Price\"\n}\n\n# Result simulated data\nW ; B ; y\ndata <- data.frame(Zeta,Y=y)\nsummary(lm(Price~.,data=data))\n# Adjusted R square of .98\n# Using 5 principal components\nkW <- 2 ; kB <- 2\n# Principal components of W\nUW <- svd(W)$u[,1:kW]\n# Principal components of B\nUB <- svd(B)$u[,1:kB]\nVB <- svd(B)$v[,1:kB]\n# creating diag wi^-1\navg.w <- matrix(0, nrow=10,ncol=126)\nfor(i in 1:10){ avg.w[i,i] <- 1/sqrt(sum(W[i,]^2))}\n# Correlation matrix C\nC <- diag(avg.w)*W%*%as.matrix(data.frame(UB,VB))\n# Explanatory variates\ndesign <- data.frame(UW,C,y)\n# Regression model\ntext.mining.mod <- lm(Price~.,data=design)\nsummary(text.mining.mod)\nplot(text.mining.mod)\n",
    "created" : 1429649230527.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "914100977",
    "id" : "BA060EF4",
    "lastKnownWriteTime" : 1429665917,
    "path" : "~/Dropbox/Academic notes/5 A/STAT 444/Project/TextMiningProject/simulation_final.R",
    "project_path" : "simulation_final.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "source_on_save" : false,
    "type" : "r_source"
}